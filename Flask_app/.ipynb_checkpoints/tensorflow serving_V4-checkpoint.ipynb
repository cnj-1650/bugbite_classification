{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serving the model -- run below to start the TF serving server\n",
    "* helpful links:\n",
    "    * https://www.analyticsvidhya.com/blog/2020/03/tensorflow-serving-deploy-deep-learning-models/\n",
    "    * https://towardsdatascience.com/deploying-deep-learning-models-using-tensorflow-serving-with-docker-and-flask-3b9a76ffbbda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "MODEL_DIR='/home/eyan/Desktop/'\n",
    "os.environ[\"MODEL_DIR\"] = MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is running in bash -- could also be run in terminal\n",
    "\n",
    "# running in the terminal\n",
    "# !tensorflow_model_server --rest_api_port=8501 --model_base_path=\"path-to-directory/tensorflow_serving/my_model\" --model_name=bug_model\n",
    "\n",
    "# alternatively, run with docker : https://towardsdatascience.com/deploying-deep-learning-models-using-tensorflow-serving-with-docker-and-flask-3b9a76ffbbda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --bg \n",
    "nohup tensorflow_model_server \\\n",
    "  --rest_api_port=8501 \\\n",
    "  --model_name=bug_model \\\n",
    "  --model_base_path=\"${MODEL_DIR}\" >server.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-11 11:57:01.209897: W external/org_tensorflow/tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 154140672 exceeds 10% of free system memory.\r\n",
      "2020-06-11 11:57:01.506307: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:183] Running initialization op on SavedModel bundle at path: /home/eyan/Desktop/1\r\n",
      "2020-06-11 11:57:01.854251: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:364] SavedModel load for tags { serve }; Status: success: OK. Took 1689891 microseconds.\r\n",
      "2020-06-11 11:57:01.915183: I tensorflow_serving/servables/tensorflow/saved_model_warmup.cc:105] No warmup data file found at /home/eyan/Desktop/1/assets.extra/tf_serving_warmup_requests\r\n",
      "2020-06-11 11:57:01.922244: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: bug_model version: 1}\r\n",
      "2020-06-11 11:57:01.924256: I tensorflow_serving/model_servers/server.cc:355] Running gRPC ModelServer at 0.0.0.0:8500 ...\r\n",
      "[evhttp_server.cc : 223] NET_LOG: Couldn't bind to port 8501\r\n",
      "[evhttp_server.cc : 63] NET_LOG: Server has not been terminated. Force termination now.\r\n",
      "[evhttp_server.cc : 258] NET_LOG: Server is not running ...\r\n",
      "2020-06-11 11:57:01.926396: E tensorflow_serving/model_servers/server.cc:377] Failed to start HTTP Server at localhost:8501\r\n"
     ]
    }
   ],
   "source": [
    "# this checks the server.log\n",
    "\n",
    "# correct serving would have \"NET_LOG: Entering the event loop ...\"\n",
    "# might need to refresh a few times before it works\n",
    "!tail server.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
