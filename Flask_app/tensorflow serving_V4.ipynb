{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serving the model -- run below to start the TF serving server\n",
    "* helpful links:\n",
    "    * https://www.analyticsvidhya.com/blog/2020/03/tensorflow-serving-deploy-deep-learning-models/\n",
    "    * https://towardsdatascience.com/deploying-deep-learning-models-using-tensorflow-serving-with-docker-and-flask-3b9a76ffbbda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "MODEL_DIR='/home/eyan/Desktop/'\n",
    "os.environ[\"MODEL_DIR\"] = MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is running in bash -- could also be run in terminal\n",
    "\n",
    "# running in the terminal\n",
    "# !tensorflow_model_server --rest_api_port=8501 --model_base_path=\"path-to-directory/tensorflow_serving/my_model\" --model_name=bug_model\n",
    "\n",
    "# alternatively, run with docker : https://towardsdatascience.com/deploying-deep-learning-models-using-tensorflow-serving-with-docker-and-flask-3b9a76ffbbda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --bg \n",
    "nohup tensorflow_model_server \\\n",
    "  --rest_api_port=8501 \\\n",
    "  --model_name=bug_model \\\n",
    "  --model_base_path=\"${MODEL_DIR}\" >server.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-12 11:29:45.310642: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:295] Reading SavedModel debug info (if present) from: /home/eyan/Desktop/1\r\n",
      "2020-06-12 11:29:45.311356: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: FMA\r\n",
      "2020-06-12 11:29:46.255785: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:234] Restoring SavedModel bundle.\r\n",
      "2020-06-12 11:29:52.112625: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:183] Running initialization op on SavedModel bundle at path: /home/eyan/Desktop/1\r\n",
      "2020-06-12 11:29:52.514194: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:364] SavedModel load for tags { serve }; Status: success: OK. Took 7437490 microseconds.\r\n",
      "2020-06-12 11:29:52.592350: I tensorflow_serving/servables/tensorflow/saved_model_warmup.cc:105] No warmup data file found at /home/eyan/Desktop/1/assets.extra/tf_serving_warmup_requests\r\n",
      "2020-06-12 11:29:52.600614: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: bug_model version: 1}\r\n",
      "2020-06-12 11:29:53.062805: I tensorflow_serving/model_servers/server.cc:355] Running gRPC ModelServer at 0.0.0.0:8500 ...\r\n",
      "2020-06-12 11:29:53.124952: I tensorflow_serving/model_servers/server.cc:375] Exporting HTTP/REST API at:localhost:8501 ...\r\n",
      "[evhttp_server.cc : 238] NET_LOG: Entering the event loop ...\r\n"
     ]
    }
   ],
   "source": [
    "# this checks the server.log\n",
    "\n",
    "# correct serving would have \"NET_LOG: Entering the event loop ...\"\n",
    "# might need to refresh a few times before it works\n",
    "!tail server.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
