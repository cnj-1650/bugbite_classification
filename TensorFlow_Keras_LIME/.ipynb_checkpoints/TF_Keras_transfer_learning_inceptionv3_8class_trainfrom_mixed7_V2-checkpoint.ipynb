{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kR-EHLnpfTV8"
      },
      "source": [
        "# Directly trian from after mixed7  -- this is the best method so far"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GagWL42bfTV9"
      },
      "outputs": [],
      "source": [
        "# import the inception model\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGDBPCT3fTV-"
      },
      "outputs": [],
      "source": [
        "# get the pretrained InceptionV3 model\n",
        "\n",
        "# include_top : whether to include the last fully connected layer -- we don't want it\n",
        "pre_trained_model = InceptionV3(input_shape = (150,150,3), include_top =False, weights = 'imagenet')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBhjYDYBfTV-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# change path to the correct path if needed\n",
        "train_data_dir = \"/content/drive/MyDrive/bug_bites_dataset/bugbite_classification-master/Resources/images/training\"\n",
        "valid_data_dir = \"/content/drive/MyDrive/bug_bites_dataset/bugbite_classification-master/Resources/images/testing\"\n",
        "\n",
        "\n",
        "batch_size=20\n",
        "\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255.,\n",
        "    shear_range=0.2,\n",
        "    rotation_range =40,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "validation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255.)\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    valid_data_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGJZNFt5fTV_"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.25 - best result so far\n",
        "x = layers.Dropout(0.25)(x)\n",
        "# Add a final softmax layer for classification\n",
        "x = layers.Dense(8,activation='softmax')(x)\n",
        "\n",
        "model = Model( pre_trained_model.input, x)\n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001),\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['acc'])\n",
        "batch_size=20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dWI1fPsfTV_"
      },
      "outputs": [],
      "source": [
        "# freeze until the mixed7 layer\n",
        "\n",
        "for layer in model.layers[:229]:\n",
        "  layer.trainable = False\n",
        "\n",
        "for layer in model.layers[229:]:\n",
        "  layer.trainable = True\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKWBnMsRfTV_"
      },
      "outputs": [],
      "source": [
        "# https://towardsdatascience.com/visualizing-intermediate-activation-in-convolutional-neural-networks-with-keras-260b36d60d0\n",
        "\n",
        "\n",
        "checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath=\"/content/drive/My_Drive/Copy of Bug Bite Classification CNN.ipynb/\",\n",
        "                               monitor = 'val_acc',\n",
        "                               verbose=1,\n",
        "                               save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrzHVUzCfTV_"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "train_steps = train_generator.samples//batch_size\n",
        "valid_steps = validation_generator.samples//batch_size\n",
        "nb_epochs = 10\n",
        "\n",
        "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "callbacks = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "history = model.fit(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = train_steps,\n",
        "            epochs = nb_epochs,\n",
        "            validation_steps = valid_steps,\n",
        "            verbose = 1,\n",
        "            callbacks=[checkpointer])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijkFqQwefTWA"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,2.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJP2R30TfTWA"
      },
      "outputs": [],
      "source": [
        "# load model with best weights\n",
        "\n",
        "model.load_weights(\"/home/eyan/Desktop/bug_bite_old/data/models/best_weights.hdf5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4sK8WQTfTWA"
      },
      "outputs": [],
      "source": [
        "# final model for use later\n",
        "model.save(\"/home/eyan/Desktop/bug_bite_old/data/models/8_class_mixed7_80p.h5\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "TensorFlow-GPU",
      "language": "python",
      "name": "tf-gpu"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}